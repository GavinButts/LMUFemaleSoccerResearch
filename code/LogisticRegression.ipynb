{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86c3c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"~/Desktop/Research/LMU_Wellness/data/Wellness_Database_May19.xlsx\", sheet_name=\"Wellness Responses\")\n",
    "\n",
    "df = df.dropna(subset=[\"How well did you hydrate?\"])\n",
    "\n",
    "sore_areas = [\"Neck\", \"Back\", \"Shoulders\", \"Chest\", \"Arms\", \"Hip Flexors\", \"Glutes\", \"Hamstrings\", \"Quadricps\", \"Adductors\", \"Calves\", \"Feet\"]\n",
    "\n",
    "columns_to_drop = ['Timestamp', 'Athlete ID #', 'Data ID', 'Week ID', 'Week ID Refined', 'Date Value', 'Year ID', 'Season ID', 'Injury Refined', 'Position', 'Classification', 'Stress RA', 'Stress StdDev', 'Stress Z-Score', 'Stress Wellness Score', 'Sleep Quality RA', 'Sleep Quality StdDev', 'Sleep Quality Z-Score', 'Sleep Quality Wellness Score', 'Sleep Quantity RA', 'Sleep Quantity StdDev', 'Sleep Quantity Z-Score', 'Sleep Quantity Wellness Score', 'Soreness RA', 'Soreness StdDev', 'Soreness Z-Score', 'Soreness Wellness Score', 'Hydrate RA', 'Hydrate StdDev', 'Hydrate Z-Score', 'Hydrate Wellness Score', 'Fuel RA', 'Fuel StdDev', 'Fuel Z-Score', 'Fuel Wellness Score', 'Readiness Score']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "df['No Injury'] = ((df['What is your injury status?'] == 'Full = I have no injury').astype(int))*10\n",
    "df['Some Injury'] = ((df['What is your injury status?'] == 'Limited = I need a modification during lift / practice').astype(int))*10\n",
    "df['Injury'] = ((df['What is your injury status?'] == 'Out = I have an injury').astype(int))*10\n",
    "\n",
    "for area in sore_areas:\n",
    "    df[area] = df.apply(lambda row: row[\"How sore are you?\"] / (row[\"Select where you are sore:\"].count(\",\")+1) if (isinstance(row[\"Select where you are sore:\"], str) and area in row[\"Select where you are sore:\"]) else 0, axis=1)\n",
    "    \n",
    "# Drop the original \"Select where you are sore:\" column\n",
    "df = df.drop(\"Select where you are sore:\", axis=1)\n",
    "\n",
    "# Drop the original column\n",
    "df = df.drop('What is your injury status?', axis=1)\n",
    "df = df.rename(columns={\"Athlete Name\": \"AthleteName\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fe333cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gbutts/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    }
   ],
   "source": [
    "#Remove outliers\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "\n",
    "# Prepare the data\n",
    "X = df.drop([\"What is your readiness score? \", \"AthleteName\"], axis=1)  # Features\n",
    "y = df[\"What is your readiness score? \"]  # Target variable\n",
    "\n",
    "# Add a constant term to the features\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the ordinary least squares (OLS) model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Compute leverage values\n",
    "leverage = OLSInfluence(results).hat_matrix_diag\n",
    "\n",
    "# Compute Cook's distance\n",
    "cooks_d = OLSInfluence(results).cooks_distance[0]\n",
    "\n",
    "# Set a threshold for identifying influential points\n",
    "threshold = 4 / len(X)  # You can adjust the threshold as needed\n",
    "\n",
    "# Identify influential points based on Cook's distance and leverage\n",
    "influential_points = np.where((cooks_d > threshold) | (leverage > np.mean(leverage) + 2 * np.std(leverage)))\n",
    "\n",
    "# Remove values\n",
    "for i in range(len(influential_points[0])):\n",
    "    df = df.drop(index = (influential_points[0][i]+1061) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e52e2f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.63839285714286"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['What is your readiness score? '].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd0d0eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['What is your readiness score? '].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d434c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df['What is your readiness score? '], bins='auto')\n",
    "plt.title(\"Readiness scores\")\n",
    "plt.show()\n",
    "\n",
    "#Cut off rate: 75\n",
    "#The average partially injured athlete is not equipped to train/perform, so \n",
    "#the average of partially injured athletes is used as cut off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d65969b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AthleteName</th>\n",
       "      <th>How stressed are you?</th>\n",
       "      <th>How well did you sleep?</th>\n",
       "      <th>How many hours did you sleep?</th>\n",
       "      <th>How sore are you?</th>\n",
       "      <th>How well did you hydrate?</th>\n",
       "      <th>How well did you fuel?</th>\n",
       "      <th>What is your readiness score?</th>\n",
       "      <th>No Injury</th>\n",
       "      <th>Some Injury</th>\n",
       "      <th>...</th>\n",
       "      <th>Shoulders</th>\n",
       "      <th>Chest</th>\n",
       "      <th>Arms</th>\n",
       "      <th>Hip Flexors</th>\n",
       "      <th>Glutes</th>\n",
       "      <th>Hamstrings</th>\n",
       "      <th>Quadricps</th>\n",
       "      <th>Adductors</th>\n",
       "      <th>Calves</th>\n",
       "      <th>Feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>Makiya Christensen</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>Ellie Sommers</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>Alice Santen</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>Kailey Park</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>Genevieve Watkins</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>Alice Santen</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>Bella Beltran</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>Gabriella Marchal</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>Makiya Christensen</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>Kailey Park</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>448 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AthleteName  How stressed are you?  How well did you sleep?  \\\n",
       "1061  Makiya Christensen                      7                        7   \n",
       "1062       Ellie Sommers                      9                        9   \n",
       "1064        Alice Santen                      6                        9   \n",
       "1065         Kailey Park                      9                        9   \n",
       "1066   Genevieve Watkins                      4                        8   \n",
       "...                  ...                    ...                      ...   \n",
       "1542        Alice Santen                      7                        9   \n",
       "1543       Bella Beltran                     10                       10   \n",
       "1544   Gabriella Marchal                     10                       10   \n",
       "1545  Makiya Christensen                      6                        8   \n",
       "1547         Kailey Park                      8                        7   \n",
       "\n",
       "      How many hours did you sleep?  How sore are you?  \\\n",
       "1061                            9.0                  6   \n",
       "1062                            8.0                  9   \n",
       "1064                            9.0                  5   \n",
       "1065                            9.0                  5   \n",
       "1066                            8.0                  4   \n",
       "...                             ...                ...   \n",
       "1542                            8.0                  8   \n",
       "1543                            8.0                  4   \n",
       "1544                            8.0                  8   \n",
       "1545                            9.0                  5   \n",
       "1547                            7.0                  6   \n",
       "\n",
       "      How well did you hydrate?  How well did you fuel?  \\\n",
       "1061                        6.0                     6.0   \n",
       "1062                        9.0                     8.0   \n",
       "1064                        7.0                     7.0   \n",
       "1065                        7.0                     8.0   \n",
       "1066                        3.0                     2.0   \n",
       "...                         ...                     ...   \n",
       "1542                        6.0                     7.0   \n",
       "1543                       10.0                    10.0   \n",
       "1544                       10.0                    10.0   \n",
       "1545                        8.0                     7.0   \n",
       "1547                        8.0                     8.0   \n",
       "\n",
       "      What is your readiness score?   No Injury  Some Injury  ...  Shoulders  \\\n",
       "1061                               0          0           10  ...   0.857143   \n",
       "1062                               1         10            0  ...   0.000000   \n",
       "1064                               0         10            0  ...   0.000000   \n",
       "1065                               1         10            0  ...   0.000000   \n",
       "1066                               0         10            0  ...   1.000000   \n",
       "...                              ...        ...          ...  ...        ...   \n",
       "1542                               0         10            0  ...   0.000000   \n",
       "1543                               0         10            0  ...   0.000000   \n",
       "1544                               1         10            0  ...   0.000000   \n",
       "1545                               1         10            0  ...   0.714286   \n",
       "1547                               0         10            0  ...   0.000000   \n",
       "\n",
       "      Chest      Arms  Hip Flexors  Glutes  Hamstrings  Quadricps  Adductors  \\\n",
       "1061    0.0  0.857143     0.857143    0.00    0.857143   0.000000   0.857143   \n",
       "1062    0.0  0.000000     2.250000    2.25    2.250000   2.250000   0.000000   \n",
       "1064    0.0  1.666667     0.000000    0.00    1.666667   1.666667   0.000000   \n",
       "1065    0.0  0.000000     2.500000    0.00    2.500000   0.000000   0.000000   \n",
       "1066    0.0  0.000000     0.000000    0.00    0.000000   1.000000   1.000000   \n",
       "...     ...       ...          ...     ...         ...        ...        ...   \n",
       "1542    0.0  0.000000     0.000000    0.00    4.000000   4.000000   0.000000   \n",
       "1543    0.0  0.000000     1.333333    0.00    1.333333   1.333333   0.000000   \n",
       "1544    0.0  0.000000     0.000000    0.00    4.000000   0.000000   0.000000   \n",
       "1545    0.0  0.714286     0.714286    0.00    0.714286   0.714286   0.000000   \n",
       "1547    0.0  3.000000     0.000000    0.00    3.000000   0.000000   0.000000   \n",
       "\n",
       "      Calves      Feet  \n",
       "1061     0.0  0.000000  \n",
       "1062     0.0  0.000000  \n",
       "1064     0.0  0.000000  \n",
       "1065     0.0  0.000000  \n",
       "1066     0.0  0.000000  \n",
       "...      ...       ...  \n",
       "1542     0.0  0.000000  \n",
       "1543     0.0  0.000000  \n",
       "1544     4.0  0.000000  \n",
       "1545     0.0  0.714286  \n",
       "1547     0.0  0.000000  \n",
       "\n",
       "[448 rows x 23 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set values above 75 to 1 and values at or below 75 to 0\n",
    "df['What is your readiness score? '] = np.where(df['What is your readiness score? '] > 75, 1, 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4edad151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gbutts/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df.drop(['What is your readiness score? ', 'AthleteName'], axis=1)  # Features\n",
    "y = df['What is your readiness score? ']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7bdfe33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6777777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df.drop(['What is your readiness score? ', 'AthleteName'], axis=1)  # Features\n",
    "y = df['What is your readiness score? ']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the logistic regression model with increased max_iter\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80434b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "nonfeatures = list(set(df.columns) - set(['How stressed are you?', 'How well did you sleep?', 'How many hours did you sleep?', 'How sore are you?', 'How well did you fuel?', 'Back', 'Shoulders', 'Chest', 'Hip Flexors', 'Glutes', 'Hamstrings', 'Quadricps', 'Calves', 'Feet', 'No Injury']))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df.drop(nonfeatures, axis=1)  # Features\n",
    "best_score = -float('inf')\n",
    "\n",
    "for n in range(10000):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=n)\n",
    "\n",
    "    # Scale the features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train the logistic regression model with increased max_iter\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    score = model.score(X_test, y_test)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_n = n\n",
    "        best_model = model\n",
    "\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf3c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
