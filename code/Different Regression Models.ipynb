{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e88d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"~/Desktop/Research/LMU_Wellness/data/Wellness_Database_May19.xlsx\", sheet_name=\"Wellness Responses\")\n",
    "\n",
    "df = df.dropna(subset=[\"How well did you hydrate?\"])\n",
    "\n",
    "sore_areas = [\"Neck\", \"Back\", \"Shoulders\", \"Chest\", \"Arms\", \"Hip Flexors\", \"Glutes\", \"Hamstrings\", \"Quadricps\", \"Adductors\", \"Calves\", \"Feet\"]\n",
    "\n",
    "for area in sore_areas:\n",
    "    df[area] = df.apply(lambda row: row[\"How sore are you?\"] / (row[\"Select where you are sore:\"].count(\",\")+1) if (isinstance(row[\"Select where you are sore:\"], str) and area in row[\"Select where you are sore:\"]) else 0, axis=1)\n",
    "\n",
    "# Drop the original \"Select where you are sore:\" column\n",
    "df = df.drop(\"Select where you are sore:\", axis=1)\n",
    "\n",
    "columns_to_drop = ['Athlete Name','Timestamp', 'Athlete ID #', 'Data ID', 'Week ID', 'Week ID Refined', 'Date Value', 'Year ID', 'Season ID', 'Injury Refined', 'Position', 'Classification', 'Stress RA', 'Stress StdDev', 'Stress Z-Score', 'Stress Wellness Score', 'Sleep Quality RA', 'Sleep Quality StdDev', 'Sleep Quality Z-Score', 'Sleep Quality Wellness Score', 'Sleep Quantity RA', 'Sleep Quantity StdDev', 'Sleep Quantity Z-Score', 'Sleep Quantity Wellness Score', 'Soreness RA', 'Soreness StdDev', 'Soreness Z-Score', 'Soreness Wellness Score', 'Hydrate RA', 'Hydrate StdDev', 'Hydrate Z-Score', 'Hydrate Wellness Score', 'Fuel RA', 'Fuel StdDev', 'Fuel Z-Score', 'Fuel Wellness Score', 'Readiness Score']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "df['No Injury'] = (df['What is your injury status?'] == 'Full = I have no injury').astype(int)*10\n",
    "df['Some Injury'] = (df['What is your injury status?'] == 'Limited = I need a modification during lift / practice').astype(int)*10\n",
    "df['Injury'] = (df['What is your injury status?'] == 'Out = I have an injury').astype(int)*10\n",
    "\n",
    "# Drop the original column\n",
    "df = df.drop('What is your injury status?', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5708bda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gbutts/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    }
   ],
   "source": [
    "#Remove outliers\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "\n",
    "# Prepare the data\n",
    "X = df.drop([\"What is your readiness score? \"], axis=1)  # Features\n",
    "y = df[\"What is your readiness score? \"]  # Target variable\n",
    "\n",
    "# Add a constant term to the features\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the ordinary least squares (OLS) model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Compute leverage values\n",
    "leverage = OLSInfluence(results).hat_matrix_diag\n",
    "\n",
    "# Compute Cook's distance\n",
    "cooks_d = OLSInfluence(results).cooks_distance[0]\n",
    "\n",
    "# Set a threshold for identifying influential points\n",
    "threshold = 4 / len(X)  # You can adjust the threshold as needed\n",
    "\n",
    "# Identify influential points based on Cook's distance and leverage\n",
    "influential_points = np.where((cooks_d > threshold) | (leverage > np.mean(leverage) + 2 * np.std(leverage)))\n",
    "\n",
    "# Remove values\n",
    "for i in range(len(influential_points[0])):\n",
    "    df = df.drop(index = (influential_points[0][i]+1061) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e0031f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ff1e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonfeatures = set(df.columns) - set(['How stressed are you?', 'How well did you sleep?', 'How many hours did you sleep?', 'How sore are you?', 'How well did you fuel?','No Injury'])\n",
    "nonfeatures = list(nonfeatures)\n",
    "\n",
    "X = df.drop(nonfeatures, axis=1) \n",
    "y = df[\"What is your readiness score? \"]  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99fd19ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression() best score is 0.5541777446047151 at state 52976\n",
      "Lasso() best score is 0.5296093231327741 at state 30627\n",
      "ElasticNet() best score is 0.5120029171263851 at state 30627\n",
      "Ridge() best score is 0.5540788715107233 at state 52976\n",
      "BayesianRidge() best score is 0.5475433938659682 at state 52976\n"
     ]
    }
   ],
   "source": [
    "models = [LinearRegression(), Lasso(), ElasticNet(), Ridge(), BayesianRidge()]\n",
    "\n",
    "for model in models:\n",
    "    best_n = 0\n",
    "    best_score = -float('inf')\n",
    "    for n in range(100000):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = n)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        if model.score(X_test, y_test) > best_score:\n",
    "            best_score = model.score(X_test, y_test)\n",
    "            best_n = n\n",
    "            \n",
    "    print(model, \"best score is\", best_score, \"at state\", best_n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "740df0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "all_columns = df.columns\n",
    "features = []\n",
    "for col in all_columns:\n",
    "    if (col != 'What is your readiness score? '):\n",
    "        features.append(col)\n",
    "\n",
    "features_combinations = []\n",
    "\n",
    "for i in range(len(features)):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    for combination in (list(itertools.combinations(features, i))):\n",
    "        features_combinations.append(combination)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "629bd7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model:\n",
      "('How well did you sleep?', 'How sore are you?', 'Neck', 'Back', 'Chest', 'Hip Flexors', 'Glutes', 'Adductors', 'No Injury')\n",
      "13.843503707538167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "best_model = None\n",
    "best_rmse = float('inf')\n",
    "best_score = -float('inf')\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X = df.drop([\"What is your readiness score? \"], axis=1)  # Features (excluding target variable)\n",
    "y = df[\"What is your readiness score? \"]  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Iterate over each feature combination\n",
    "for feature_comb in features_combinations:\n",
    "    # Prepare the training data\n",
    "    X_train_comb = X_train[list(feature_comb)]\n",
    "\n",
    "    # Fit a linear regression model\n",
    "    model = Ridge()\n",
    "    model.fit(X_train_comb, y_train)\n",
    "\n",
    "    # Prepare the test data\n",
    "    X_test_comb = X_test[list(feature_comb)]\n",
    "\n",
    "    # Predict using the model\n",
    "    y_pred = model.predict(X_test_comb)\n",
    "\n",
    "    # Calculate RMSE (Root Mean Squared Error) & Score (R^2)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    score = model.score(X_test_comb, y_test)\n",
    "\n",
    "    # Check if this model performs better than the previous best model\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_model = model\n",
    "        best_feature_comb = feature_comb\n",
    "        \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_score_model = model\n",
    "        best_score_feature_comb = feature_comb\n",
    "\n",
    "# Print the best model\n",
    "print(\"Best Model:\")\n",
    "print(best_feature_comb)\n",
    "print(best_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1296dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2562967153533754"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa57a380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
